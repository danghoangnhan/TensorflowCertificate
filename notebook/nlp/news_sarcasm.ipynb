{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T50oOXGkpeNE"
      },
      "source": [
        "# Đề thi mẫu chứng chỉ TensorFlow - Dạng bài 04\n",
        "\n",
        "```\n",
        "ProtonX - TensorFlow Class\n",
        "```\n",
        "Giới thiệu về chứng chỉ - https://www.tensorflow.org/certificate\n",
        "\n",
        "> Chú ý: đọc kỹ các nội dung trong Handle Notebook trong liên kết trên.\n",
        "\n",
        "---\n",
        "\n",
        "**Bài toán: Phân loại câu mỉa mai !**\n",
        "\n",
        "### Hướng dẫn làm bài  \n",
        "- Trong phần bài tập này, các bạn sẽ thực hiện tương tự bài IMDB Dataset.\n",
        "\n",
        "Yêu cầu:\n",
        "- Sử dụng TensorFlow.\n",
        "- Sử dụng Callback.\n",
        "- Sử dụng các mạng LSTM, GRU, Bi-LSTM, v.v...\n",
        "- Tỷ lệ chính xác trên tập Test > 85 - 87%.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf_84ca-p63U"
      },
      "source": [
        "### Thực hiện\n",
        "\n",
        "Dataset: https://rishabhmisra.github.io/publications/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0RJ22Fzp6eq",
        "outputId": "3f98ee79-7075-4318-fc3e-57782b5c4c21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-10-10 16:59:10--  https://storage.googleapis.com/learning-datasets/sarcasm.json\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.191.207, 173.194.74.207, 173.194.192.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.191.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5643545 (5.4M) [application/json]\n",
            "Saving to: ‘/tmp/sarcasm.json’\n",
            "\n",
            "\r/tmp/sarcasm.json     0%[                    ]       0  --.-KB/s               \r/tmp/sarcasm.json   100%[===================>]   5.38M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2023-10-10 16:59:10 (97.6 MB/s) - ‘/tmp/sarcasm.json’ saved [5643545/5643545]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Hướng dẫn về bộ dữ liệu này được thực hiện trong Lab Tokenizer\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/learning-datasets/sarcasm.json \\\n",
        "    -O /tmp/sarcasm.json\n",
        "\n",
        "import json\n",
        "\n",
        "with open(\"/tmp/sarcasm.json\", 'r') as f:\n",
        "    datastore = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcT8Xu2QP-zV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbOT4-5WD-Gv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "dataset = []\n",
        "label_dataset = []\n",
        "for item in datastore:\n",
        "    dataset.append(item[\"headline\"])\n",
        "    label_dataset.append(item[\"is_sarcastic\"])\n",
        "\n",
        "dataset = np.array(dataset)\n",
        "label_dataset = np.array(label_dataset)\n",
        "train_size = 0.8\n",
        "size = int(len(dataset) * train_size)\n",
        "\n",
        "train_sentence = dataset[:size]\n",
        "test_sentence = dataset[size:]\n",
        "\n",
        "train_label = label_dataset[:size]\n",
        "test_label = label_dataset[size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vk7m6w8wPp77"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(train_sentence)\n",
        "embedding_size = 64\n",
        "max_length = 25\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(train_sentence)\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(train_sentence)\n",
        "padded_train_sequences = pad_sequences(train_sequences, maxlen=max_length, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(test_sentence)\n",
        "padded_test_sequences = pad_sequences(test_sequences, maxlen=max_length, truncating=\"post\", padding=\"post\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JbDK6nnXB60"
      },
      "outputs": [],
      "source": [
        "units = 128\n",
        "embedding_size = 100\n",
        "vocab_size = len(tokenizer.index_word) + 1\n",
        "input_length = max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMM_TEqmVctb"
      },
      "outputs": [],
      "source": [
        "model_lstm = tf.keras.Sequential([\n",
        "  tf.keras.layers.Embedding(vocab_size, 64),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "#https://www.kaggle.com/code/nikhilkohli/sarcasm-detection-using-lstm-gru-85-accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-G-eIXlp3CY",
        "outputId": "4e0ea9e2-f13a-4155-aee3-0c28cbdfb20c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "668/668 [==============================] - 56s 33ms/step - loss: 0.3892 - acc: 0.8121 - val_loss: 0.3295 - val_acc: 0.8598 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "668/668 [==============================] - 10s 15ms/step - loss: 0.1711 - acc: 0.9341 - val_loss: 0.3576 - val_acc: 0.8560 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "668/668 [==============================] - 9s 14ms/step - loss: 0.0715 - acc: 0.9752 - val_loss: 0.4665 - val_acc: 0.8501 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "668/668 [==============================] - 9s 13ms/step - loss: 0.0235 - acc: 0.9927 - val_loss: 0.5828 - val_acc: 0.8529 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "668/668 [==============================] - 10s 15ms/step - loss: 0.0135 - acc: 0.9963 - val_loss: 0.6553 - val_acc: 0.8532 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "668/668 [==============================] - 10s 14ms/step - loss: 0.0086 - acc: 0.9980 - val_loss: 0.6711 - val_acc: 0.8521 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "668/668 [==============================] - 9s 13ms/step - loss: 0.0081 - acc: 0.9984 - val_loss: 0.6881 - val_acc: 0.8525 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "668/668 [==============================] - 8s 12ms/step - loss: 0.0077 - acc: 0.9985 - val_loss: 0.6899 - val_acc: 0.8527 - lr: 1.0000e-06\n",
            "Epoch 9/100\n",
            "668/668 [==============================] - 9s 14ms/step - loss: 0.0077 - acc: 0.9985 - val_loss: 0.6919 - val_acc: 0.8525 - lr: 1.0000e-06\n",
            "Epoch 10/100\n",
            "668/668 [==============================] - 8s 12ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6922 - val_acc: 0.8525 - lr: 1.0000e-07\n",
            "Epoch 11/100\n",
            "668/668 [==============================] - 8s 12ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-07\n",
            "Epoch 12/100\n",
            "668/668 [==============================] - 8s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-08\n",
            "Epoch 13/100\n",
            "668/668 [==============================] - 9s 14ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-08\n",
            "Epoch 14/100\n",
            "668/668 [==============================] - 9s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-09\n",
            "Epoch 15/100\n",
            "668/668 [==============================] - 8s 12ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-09\n",
            "Epoch 16/100\n",
            "668/668 [==============================] - 8s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-10\n",
            "Epoch 17/100\n",
            "668/668 [==============================] - 8s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-10\n",
            "Epoch 18/100\n",
            "668/668 [==============================] - 7s 11ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-11\n",
            "Epoch 19/100\n",
            "668/668 [==============================] - 9s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-11\n",
            "Epoch 20/100\n",
            "668/668 [==============================] - 9s 14ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-12\n",
            "Epoch 21/100\n",
            "668/668 [==============================] - 10s 15ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-12\n",
            "Epoch 22/100\n",
            "668/668 [==============================] - 8s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-13\n",
            "Epoch 23/100\n",
            "668/668 [==============================] - 8s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-13\n",
            "Epoch 24/100\n",
            "668/668 [==============================] - 9s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-14\n",
            "Epoch 25/100\n",
            "668/668 [==============================] - 7s 11ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-14\n",
            "Epoch 26/100\n",
            "668/668 [==============================] - 8s 12ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-15\n",
            "Epoch 27/100\n",
            "668/668 [==============================] - 8s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-15\n",
            "Epoch 28/100\n",
            "668/668 [==============================] - 8s 12ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-16\n",
            "Epoch 29/100\n",
            "668/668 [==============================] - 9s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-16\n",
            "Epoch 30/100\n",
            "668/668 [==============================] - 8s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-17\n",
            "Epoch 31/100\n",
            "668/668 [==============================] - 8s 12ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-17\n",
            "Epoch 32/100\n",
            "668/668 [==============================] - 8s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-18\n",
            "Epoch 33/100\n",
            "668/668 [==============================] - 9s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-18\n",
            "Epoch 34/100\n",
            "668/668 [==============================] - 8s 12ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-19\n",
            "Epoch 35/100\n",
            "668/668 [==============================] - 9s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-19\n",
            "Epoch 36/100\n",
            "668/668 [==============================] - 8s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-20\n",
            "Epoch 37/100\n",
            "668/668 [==============================] - 8s 12ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-20\n",
            "Epoch 38/100\n",
            "668/668 [==============================] - 9s 14ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-21\n",
            "Epoch 39/100\n",
            "668/668 [==============================] - 10s 15ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-21\n",
            "Epoch 40/100\n",
            "668/668 [==============================] - 10s 14ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-22\n",
            "Epoch 41/100\n",
            "668/668 [==============================] - 8s 12ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-22\n",
            "Epoch 42/100\n",
            "668/668 [==============================] - 8s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-23\n",
            "Epoch 43/100\n",
            "668/668 [==============================] - 9s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-23\n",
            "Epoch 44/100\n",
            "668/668 [==============================] - 8s 12ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-24\n",
            "Epoch 46/100\n",
            "668/668 [==============================] - 9s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-25\n",
            "Epoch 47/100\n",
            "668/668 [==============================] - 9s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-25\n",
            "Epoch 48/100\n",
            "668/668 [==============================] - 8s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-26\n",
            "Epoch 49/100\n",
            "668/668 [==============================] - 9s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-26\n",
            "Epoch 50/100\n",
            "668/668 [==============================] - 9s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-27\n",
            "Epoch 51/100\n",
            "668/668 [==============================] - 8s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-27\n",
            "Epoch 52/100\n",
            "668/668 [==============================] - 9s 14ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-28\n",
            "Epoch 53/100\n",
            "668/668 [==============================] - 9s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-28\n",
            "Epoch 54/100\n",
            "668/668 [==============================] - 8s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-29\n",
            "Epoch 55/100\n",
            "668/668 [==============================] - 8s 12ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-29\n",
            "Epoch 56/100\n",
            "668/668 [==============================] - 9s 14ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-30\n",
            "Epoch 57/100\n",
            "668/668 [==============================] - 8s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-30\n",
            "Epoch 58/100\n",
            "668/668 [==============================] - 8s 12ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-31\n",
            "Epoch 59/100\n",
            "668/668 [==============================] - 9s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-31\n",
            "Epoch 60/100\n",
            "668/668 [==============================] - 8s 12ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-32\n",
            "Epoch 61/100\n",
            "668/668 [==============================] - 8s 11ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-32\n",
            "Epoch 62/100\n",
            "668/668 [==============================] - 8s 12ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-33\n",
            "Epoch 63/100\n",
            "668/668 [==============================] - 9s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-33\n",
            "Epoch 64/100\n",
            "668/668 [==============================] - 8s 12ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-34\n",
            "Epoch 65/100\n",
            "668/668 [==============================] - 9s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-34\n",
            "Epoch 66/100\n",
            "668/668 [==============================] - 9s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-35\n",
            "Epoch 67/100\n",
            "668/668 [==============================] - 8s 12ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-35\n",
            "Epoch 68/100\n",
            "668/668 [==============================] - 8s 12ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-36\n",
            "Epoch 69/100\n",
            "668/668 [==============================] - 8s 12ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-36\n",
            "Epoch 70/100\n",
            "668/668 [==============================] - 8s 11ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-37\n",
            "Epoch 71/100\n",
            "668/668 [==============================] - 8s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-37\n",
            "Epoch 72/100\n",
            "668/668 [==============================] - 9s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-38\n",
            "Epoch 73/100\n",
            "668/668 [==============================] - 8s 11ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-38\n",
            "Epoch 74/100\n",
            "668/668 [==============================] - 9s 14ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-39\n",
            "Epoch 75/100\n",
            "668/668 [==============================] - 8s 12ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0000e-39\n",
            "Epoch 76/100\n",
            "668/668 [==============================] - 8s 12ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 9.9999e-41\n",
            "Epoch 77/100\n",
            "668/668 [==============================] - 9s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 9.9999e-41\n",
            "Epoch 78/100\n",
            "668/668 [==============================] - 8s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 9.9997e-42\n",
            "Epoch 79/100\n",
            "668/668 [==============================] - 9s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 9.9997e-42\n",
            "Epoch 80/100\n",
            "668/668 [==============================] - 8s 12ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0005e-42\n",
            "Epoch 81/100\n",
            "668/668 [==============================] - 9s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.0005e-42\n",
            "Epoch 82/100\n",
            "668/668 [==============================] - 8s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 9.9492e-44\n",
            "Epoch 83/100\n",
            "668/668 [==============================] - 8s 12ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 9.9492e-44\n",
            "Epoch 84/100\n",
            "668/668 [==============================] - 8s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 9.8091e-45\n",
            "Epoch 85/100\n",
            "668/668 [==============================] - 8s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 9.8091e-45\n",
            "Epoch 86/100\n",
            "668/668 [==============================] - 8s 12ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.4013e-45\n",
            "Epoch 87/100\n",
            "668/668 [==============================] - 8s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 1.4013e-45\n",
            "Epoch 88/100\n",
            "668/668 [==============================] - 8s 12ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 0.0000e+00\n",
            "Epoch 89/100\n",
            "668/668 [==============================] - 8s 12ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 0.0000e+00\n",
            "Epoch 90/100\n",
            "668/668 [==============================] - 8s 12ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 0.0000e+00\n",
            "Epoch 91/100\n",
            "668/668 [==============================] - 9s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 0.0000e+00\n",
            "Epoch 92/100\n",
            "668/668 [==============================] - 8s 12ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 0.0000e+00\n",
            "Epoch 93/100\n",
            "668/668 [==============================] - 9s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 0.0000e+00\n",
            "Epoch 94/100\n",
            "668/668 [==============================] - 9s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 0.0000e+00\n",
            "Epoch 95/100\n",
            "668/668 [==============================] - 9s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 0.0000e+00\n",
            "Epoch 96/100\n",
            "668/668 [==============================] - 9s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 0.0000e+00\n",
            "Epoch 97/100\n",
            "668/668 [==============================] - 10s 14ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 0.0000e+00\n",
            "Epoch 98/100\n",
            "668/668 [==============================] - 9s 14ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 0.0000e+00\n",
            "Epoch 99/100\n",
            "668/668 [==============================] - 8s 12ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 0.0000e+00\n",
            "Epoch 100/100\n",
            "668/668 [==============================] - 9s 13ms/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.6924 - val_acc: 0.8525 - lr: 0.0000e+00\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c4fa850a560>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rlrp = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2)\n",
        "model_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "model_lstm.fit(\n",
        "    padded_train_sequences, train_label,\n",
        "    batch_size=32,\n",
        "    epochs=100,\n",
        "    validation_data=(padded_test_sequences, test_label),\n",
        "    callbacks=[rlrp] ,\n",
        "    verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWVZK-8hnovk",
        "outputId": "b72e5c50-0254-4a13-9b9e-18dd4ed3e377"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# Lưu Model và nộp\n",
        "model_lstm.save(\"sarcasm_model_lstm.h5\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
