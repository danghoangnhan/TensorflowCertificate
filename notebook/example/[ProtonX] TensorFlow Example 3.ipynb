{"cells":[{"cell_type":"markdown","metadata":{"id":"1Q0tt_iI0PYO"},"source":["# Đề thi mẫu chứng chỉ TensorFlow - Dạng bài 03\n","\n","```\n","ProtonX - TensorFlow Class \n","```\n","Giới thiệu về chứng chỉ - https://www.tensorflow.org/certificate\n","\n","> Chú ý: đọc kỹ các nội dung trong Handle Notebook trong liên kết trên.\n","\n","---\n","\n","### Hướng dẫn làm bài \n","\n","Đọc kỹ File `Tensorflow Exam - Tips` trên hệ thống Học tập.\n","\n","*Một số yêu cầu:\n","- Sử dụng TensorFlow 2.x trở lên.\n","\n","Phân loại ảnh thực tế:\n","- Một số loại dataset thường gặp trong đề thi: Chó - mèo, Ngựa - người, Dao - Búa - Kéo.\n","- Có thể đề yêu cầu load data từ tf.dataset. Đề bài có thể yêu cầu resize ảnh về kích thước nào đó (ví dụ 224x224x3) và re-scale input về khoảng [-1, 1]. Thực hiện resize và rescale ảnh trong hàm map:\n","https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map\n","\n","- Lưu ý 1: Có thể sử dụng Transfer learning - ưu tiên MobileNet để Train mô hình có độ chính xác cao hơn.\n","- Lưu ý 2: Phân loại nhị phân nhưng đề bài có thể yêu cầu lớp cuối cùng của model phải sử dụng hàm softmax(thay vì sigmoid), vì vậy cần chọn làm loss phù hợp với hàm softmax.\n","- flow_from_directory + generator\n","  + Chó mèo: https://youtu.be/kShvYHDXvvg\n","  + Ngựa người: https://youtu.be/ee9tF9xEf04\n","  + Dao búa kéo: https://www.tensorflow.org/datasets/catalog/rock_paper_scissors\n","  + Cách resize ảnh, rescale input và transfer learning có thể tham khảo: https://www.tensorflow.org/tutorials/images/transfer_learning\n","https://youtu.be/Y-4KLFt_c6Y\n","\n","- Bài sử dụng transfer learning có thể có kết quả khi submit là 2/5, 3/5, …. Vì vậy nên submit nhiều lần. Nếu đạt từ 4/5 trở lên thì có thể làm bài khác (áp dụng với tất cả các bài)\n","\n","- Chạy lại toàn bộ File này trước khi ấn nộp bài."]},{"cell_type":"markdown","metadata":{"id":"Aip0oolq0lvW"},"source":["### Đề thi mẫu bài 03"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"7zGptboWz-UI"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-10-07 21:01:36.824941: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"name":"stdout","output_type":"stream","text":["2.12.0\n"]}],"source":["# TensorFlow and tf.keras\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Helper libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","print(tf.__version__)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"m0e7vIMt0paf"},"outputs":[{"name":"stdout","output_type":"stream","text":["/bin/bash: /home/danieldu/anaconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n","wget: /home/danieldu/anaconda3/lib/libuuid.so.1: no version information available (required by wget)\n","--2023-10-07 21:01:40--  https://storage.googleapis.com/download.tensorflow.org/data/rps.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.160.91, 142.251.42.251, 172.217.163.59, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.160.91|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 200682221 (191M) [application/zip]\n","Saving to: ‘/tmp/rockpaperscissors.zip’\n","\n","/tmp/rockpapersciss 100%[===================>] 191.38M  1.11MB/s    in 2m 54s  \n","\n","2023-10-07 21:04:35 (1.10 MB/s) - ‘/tmp/rockpaperscissors.zip’ saved [200682221/200682221]\n","\n"]}],"source":["# Các bạn có thể tải dữ liệu bằng đường liên kết này \n","!wget https://storage.googleapis.com/download.tensorflow.org/data/rps.zip -O /tmp/rockpaperscissors.zip"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"_huSioYWGYmI"},"outputs":[],"source":["# Hoặc tải dữ liệu trong TensorFlow Dataset\n","DATASET_NAME = 'rock_paper_scissors'"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"aPbREJKU0zb6"},"outputs":[],"source":["# Write your code here \n","training_datagen = ImageDataGenerator(\n","      rescale = 1./255,\n","\t    rotation_range=40,\n","      width_shift_range=0.2,\n","      height_shift_range=0.2,\n","      shear_range=0.2,\n","      zoom_range=0.2,\n","      horizontal_flip=True,\n","      fill_mode='nearest')\n","\n","VALIDATION_DIR = \"/tmp/rps-test-set/\"\n","validation_datagen = ImageDataGenerator(rescale = 1./255)\n","\n","train_generator = training_datagen.flow_from_directory(\n","\tTRAINING_DIR,\n","\ttarget_size=(150,150),\n","\tclass_mode='categorical',\n","  batch_size=126\n",")\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","\tVALIDATION_DIR,\n","\ttarget_size=(150,150),\n","\tclass_mode='categorical',\n","  batch_size=126\n",")\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"IhPI_RQF0sgI"},"outputs":[{"ename":"SyntaxError","evalue":"invalid syntax (3961098768.py, line 1)","output_type":"error","traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[5], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    model = # TODO\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}],"source":["model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.Dense(512, activation='relu'),\n","    tf.keras.layers.Dense(3, activation='softmax')\n","    ])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qAPvZsvY0s3t"},"outputs":[],"source":["# Train model \n","model.summary()\n","model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n","history = model.fit(train_generator, epochs=25, steps_per_epoch=20, validation_data = validation_generator, verbose =1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DbqnLrMZ05TJ"},"outputs":[],"source":["# Lưu Model và nộp \n","model.save(\"mymodel.h5\")"]}],"metadata":{"colab":{"provenance":[{"file_id":"1iEheosm5rJmMJIaTdrCXcWe-EoZPY8Ff","timestamp":1641979212910}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}
